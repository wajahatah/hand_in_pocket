{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60079be",
   "metadata": {},
   "source": [
    "### Annotation\n",
    "Annotate each video and save data in the csv and rename the videos also,\n",
    "Take input for each person hand in pocket and can also automate the annotation for one person if press a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3bedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The script is used to annotate hand in pocket videos and generating a csv file with the keypoints and distances values. \n",
    "It take camera number and video number as input and name the csv file to that number with camera number and video number as cN_vN.\"\"\"\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "roi_data_list = []\n",
    "frame_count = 0\n",
    "saved_TP_frames = set()\n",
    "\n",
    "\n",
    "def draw_lines(frame, keypoints, connections):\n",
    "    for start_idx, end_idx in connections:\n",
    "        if start_idx < len(keypoints) and end_idx < len(keypoints):\n",
    "            x1, y1, conf1 = keypoints[start_idx]\n",
    "            x2, y2, conf2 = keypoints[end_idx]\n",
    "            if conf1 > 0.5 and conf2 > 0.5:\n",
    "                cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n",
    "\n",
    "def assign_roi_index(x):\n",
    "    for roi in roi_data_list:\n",
    "        if roi[\"xmin\"] <= x < roi[\"xmax\"]:\n",
    "            return roi[\"desk\"]\n",
    "    return -1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = YOLO(\"C:/wajahat/hand_in_pocket/bestv8-1.pt\")\n",
    "    input_dir = \"C:/Users/LT/Downloads/TP_S2/TP_S2\"\n",
    "    # video_name = \"c2_v4\"\n",
    "    output_dir = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_s2_w1\"\n",
    "    # json_path = \"qiyas_multicam.camera_final.json\"\n",
    "    json_path = \"qiyas_multicam_2.camera.json\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    video_files = [f for f in os.listdir(input_dir) if f.endswith(\".mp4\")]\n",
    "    if not video_files:\n",
    "        print(\"No video files found in the input directory.\")\n",
    "        exit()\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        video_path = os.path.join(input_dir, video_file)\n",
    "        print(f\"Processing {video_name}...\")\n",
    "    \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open video.\")\n",
    "            exit()\n",
    "\n",
    "        frame_width = 1280\n",
    "        frame_height = 720\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error reading first frame.\")\n",
    "            exit()\n",
    "\n",
    "        frame = cv2.resize(frame, (1280, 720))\n",
    "        cv2.imshow(\"Select Camera View\", frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        with open(json_path, \"r\") as f:\n",
    "            camera_config = json.load(f)\n",
    "\n",
    "        skip_video = False\n",
    "        while True:\n",
    "            cam_id = input(\"Enter camera ID: \")\n",
    "            if cam_id.lower() == 's':\n",
    "                with open(f\"{output_dir}/video_skip.csv\", \"a\", newline='') as f:\n",
    "                    f.write(f\"skipped the video: {video_file} \\n\")\n",
    "                skip_video = True\n",
    "                cap.release()\n",
    "                cv2.destroyWindow(\"Select Camera View\")\n",
    "                break\n",
    "            camera_id_input = cam_id\n",
    "            video_num = input(\"Enter video num:\")\n",
    "            camera_id = f\"camera_{camera_id_input}\"\n",
    "            camera_data = next((cam for cam in camera_config if cam[\"_id\"] == camera_id), None)\n",
    "            if camera_data:\n",
    "                break\n",
    "            print(f\"Invalid camera ID: {camera_id}. Please try again.\")\n",
    "\n",
    "        if skip_video:\n",
    "            continue\n",
    "\n",
    "        cv2.destroyWindow(\"Select Camera View\")\n",
    "\n",
    "        roi_data_list = list(camera_data[\"data\"].values())\n",
    "        roi_lookup = {roi[\"desk\"]: roi for roi in roi_data_list}\n",
    "\n",
    "        connections = [\n",
    "            (0, 1), (0, 2), (0, 3),\n",
    "            (1, 4), (1, 7),\n",
    "            (4, 5), (5, 6),\n",
    "            (7, 8), (8, 9)\n",
    "        ]\n",
    "        video_name = f\"c{camera_id_input}_v{video_num}\"\n",
    "        csv_filename = os.path.join(output_dir, video_name + \".csv\")\n",
    "\n",
    "        keypoint_headers = [f\"kp_{i}_x\" for i in range(10)] + [f\"kp_{i}_y\" for i in range(10)] + [f\"kp_{i}_conf\" for i in range(10)]\n",
    "        headers = [\"frame\", \"person_idx\", \"position\", \"desk_no\"] + keypoint_headers + [\"hand_in_pocket\"]\n",
    "\n",
    "        csv_file = open(csv_filename, \"w\", newline=\"\")\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "        csv_writer.writeheader()\n",
    "\n",
    "        all_frames_data = []\n",
    "        frame_count = 0\n",
    "        processed_videos= []\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, (1280, 720))\n",
    "            results = model(frame, verbose=False)\n",
    "            person_info_list = []\n",
    "\n",
    "            for result in results:\n",
    "                keypoints = result.keypoints\n",
    "                if keypoints is not None:\n",
    "                    keypoints_data = keypoints.data\n",
    "\n",
    "                    temp_person_info = []\n",
    "\n",
    "                    for person_keypoints in keypoints_data:\n",
    "                        keypoint_list = []\n",
    "                        row_data = {\"frame\": frame_count}\n",
    "\n",
    "                        for kp_idx, kp in enumerate(person_keypoints):\n",
    "                            x, y, conf = kp[0].item(), kp[1].item(), kp[2].item()\n",
    "                            if conf < 0.5:\n",
    "                                x, y = 0, 0\n",
    "                            keypoint_list.append((x, y, conf))\n",
    "                            row_data[f\"kp_{kp_idx}_x\"] = x\n",
    "                            row_data[f\"kp_{kp_idx}_y\"] = y\n",
    "                            row_data[f\"kp_{kp_idx}_conf\"] = conf\n",
    "                            if conf > 0.5:\n",
    "                                cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "\n",
    "                                draw_lines(frame, keypoint_list, connections)\n",
    "\n",
    "                        if not keypoint_list:\n",
    "                            continue\n",
    "\n",
    "                        roi_x = keypoint_list[0][0]\n",
    "                        roi_idx = assign_roi_index(roi_x)\n",
    "                        roi_data = roi_lookup.get(roi_idx)\n",
    "\n",
    "                        if roi_data is None:\n",
    "                            print(f\"⚠️ No ROI config for roi_idx {roi_idx}, skipping.\")\n",
    "                            continue\n",
    "\n",
    "                        cv2.putText(frame, f\"ROI: {roi_idx}\", (int(roi_x), 50 + 30 * roi_idx), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                        \n",
    "                        row_data[\"desk_no\"] = roi_idx\n",
    "                        row_data[\"position\"] = roi_data[\"position\"]\n",
    "\n",
    "                        temp_person_info.append((roi_idx, row_data))\n",
    "\n",
    "\n",
    "                    # Remap person_idx based on sorted roi\n",
    "                    temp_person_info.sort(key=lambda x: x[0])\n",
    "                    for new_idx, (_, row) in enumerate(temp_person_info):\n",
    "                        row[\"person_idx\"] = new_idx\n",
    "                        person_info_list.append(row)\n",
    "\n",
    "            all_frames_data.append((frame.copy(), person_info_list))\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Rearranged annotation loop by person across all frames\n",
    "        max_persons = max(len(info) for _, info in all_frames_data)\n",
    "        print(max_persons)\n",
    "\n",
    "        frame_hand_labels = {}\n",
    "        auto_labels = {}\n",
    "        for person_idx in range(max_persons):\n",
    "            print(f\"\\n\\u25ba Now annotating for Person #{roi_idx} of video {video_name}across all frames.\")\n",
    "\n",
    "            for frame_num, (frame, person_list) in enumerate(all_frames_data):\n",
    "                if person_idx >= len(person_list):\n",
    "                    continue\n",
    "                row_data = person_list[person_idx]\n",
    "                frame_to_show = frame.copy()\n",
    "                save_frame = frame_to_show.copy()\n",
    "\n",
    "                cv2.imshow(\"frame\", frame_to_show)\n",
    "                cv2.waitKey(1)\n",
    "\n",
    "                roi_idx = row_data[\"desk_no\"]\n",
    "                position = row_data[\"position\"]\n",
    "                prompt = f\"Frame {frame_num} | ROI {roi_idx} (Position: {position}): Enter hand_in_pocket (0 or 1) [Default: 0]: \"\n",
    "\n",
    "                if roi_idx in auto_labels:\n",
    "                    hand_in_pocket = auto_labels[roi_idx]\n",
    "                    print(f\"Auto label applird: ROI {roi_idx} -> {hand_in_pocket}\")\n",
    "                \n",
    "                else:\n",
    "                    while True:\n",
    "                        hand_in_pocket = input(prompt).strip()\n",
    "                        if hand_in_pocket.lower() == \"a\":\n",
    "                            value = input(f\"Enter value for ROI {roi_idx} (0 or 1): \").strip()\n",
    "                            if value not in [\"0\", \"1\"]:\n",
    "                                print(\"❌ Invalid value. Please enter 0 or 1.\")\n",
    "                                continue\n",
    "                            auto_labels[roi_idx] = value\n",
    "                            hand_in_pocket = value\n",
    "                            print(f\"Auto label set: ROI {roi_idx} -> {hand_in_pocket}\")\n",
    "                            break\n",
    "\n",
    "                        elif hand_in_pocket in [\"\",\"0\",\"1\"]:\n",
    "                            hand_in_pocket = hand_in_pocket or \"0\"\n",
    "                            break\n",
    "\n",
    "                        else:\n",
    "                            print(\"❌ Invalid input. Please enter 0 or 1 or press Enter for default 0.\")\n",
    "\n",
    "                row_data[\"hand_in_pocket\"] = hand_in_pocket\n",
    "                csv_writer.writerow(row_data)\n",
    "            \n",
    "        new_video_path = os.path.join(input_dir, video_name + \".mp4\")\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(new_video_path):\n",
    "                os.remove(new_video_path)\n",
    "\n",
    "            shutil.copy2(video_path, new_video_path)\n",
    "            print(f\"Copied processed video to: {new_video_path}\")\n",
    "\n",
    "            try:\n",
    "                if os.path.getsize(video_path) != os.path.getsize(new_video_path):\n",
    "                    print(\"⚠️ Warning: copied file size differs from source.\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            if os.path.exists(video_path):\n",
    "                os.remove(video_path)\n",
    "                print(f\"Deleted original video: {video_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Video copy/overwrite/delete failed: {e}\")\n",
    "\n",
    "    csv_file.close()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be27de1b",
   "metadata": {},
   "source": [
    "### FP Annotation\n",
    "Annotation of FP videos to assign automatically all data to 0, just need to enter the video num and it will create csv and rename the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# Global variable to hold loaded ROI data\n",
    "roi_data_list = []\n",
    "frame_count = 0\n",
    "saved_TP_frames = set()\n",
    "\n",
    "\n",
    "def draw_lines(frame, keypoints, connections):\n",
    "    for start_idx, end_idx in connections:\n",
    "        if start_idx < len(keypoints) and end_idx < len(keypoints):\n",
    "            x1, y1, conf1 = keypoints[start_idx]\n",
    "            x2, y2, conf2 = keypoints[end_idx]\n",
    "            if conf1 > 0.5 and conf2 > 0.5:\n",
    "                cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n",
    "\n",
    "def assign_roi_index(x):\n",
    "    for roi in roi_data_list:\n",
    "        if roi[\"xmin\"] <= x < roi[\"xmax\"]:\n",
    "            return roi[\"desk\"]\n",
    "    return -1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = YOLO(\"C:/wajahat/hand_in_pocket/bestv8-1.pt\")\n",
    "    input_dir = \"C:/Users/LT/Downloads/fp/fp\"\n",
    "    # video_name = \"c2_v4\"\n",
    "    output_dir = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_s2_w1\"\n",
    "    # json_path = \"qiyas_multicam.camera_final.json\"\n",
    "    json_path = \"qiyas_multicam_2.camera.json\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    video_files = [f for f in os.listdir(input_dir) if f.endswith(\".mp4\")]\n",
    "    if not video_files:\n",
    "        print(\"No video files found in the input directory.\")\n",
    "        exit()\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        video_path = os.path.join(input_dir, video_file)\n",
    "        print(f\"Processing {video_name}...\")\n",
    "    \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open video.\")\n",
    "            exit()\n",
    "\n",
    "        frame_width = 1280\n",
    "        frame_height = 720\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error reading first frame.\")\n",
    "            exit()\n",
    "\n",
    "        frame = cv2.resize(frame, (1280, 720))\n",
    "        cv2.imshow(\"Select Camera View\", frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        with open(json_path, \"r\") as f:\n",
    "            camera_config = json.load(f)\n",
    "\n",
    "        while True:\n",
    "            camera_id_input = input(\"Enter camera ID for this video (e.g., camera_1): \")\n",
    "            video_num = input(\"Enter video name:\")\n",
    "            camera_id = f\"camera_{camera_id_input}\"\n",
    "            camera_data = next((cam for cam in camera_config if cam[\"_id\"] == camera_id), None)\n",
    "            if camera_data:\n",
    "                break\n",
    "            print(f\"Invalid camera ID: {camera_id}. Please try again.\")\n",
    "\n",
    "        cv2.destroyWindow(\"Select Camera View\")\n",
    "\n",
    "        roi_data_list = list(camera_data[\"data\"].values())\n",
    "        roi_lookup = {roi[\"desk\"]: roi for roi in roi_data_list}\n",
    "\n",
    "        connections = [\n",
    "            (0, 1), (0, 2), (0, 3),\n",
    "            (1, 4), (1, 7),\n",
    "            (4, 5), (5, 6),\n",
    "            (7, 8), (8, 9)\n",
    "        ]\n",
    "        video_name = f\"c{camera_id_input}_v{video_num}\"\n",
    "        csv_filename = os.path.join(output_dir, video_name + \".csv\")\n",
    "\n",
    "        keypoint_headers = [f\"kp_{i}_x\" for i in range(10)] + [f\"kp_{i}_y\" for i in range(10)] + [f\"kp_{i}_conf\" for i in range(10)]\n",
    "        headers = [\"frame\", \"person_idx\", \"position\", \"desk_no\"] + keypoint_headers + [\"hand_in_pocket\"]\n",
    "\n",
    "        csv_file = open(csv_filename, \"w\", newline=\"\")\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "        csv_writer.writeheader()\n",
    "\n",
    "        all_frames_data = []\n",
    "        frame_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, (1280, 720))\n",
    "            save_frame = frame.copy()\n",
    "            results = model(frame, verbose=False)\n",
    "            person_info_list = []\n",
    "\n",
    "            for result in results:\n",
    "                keypoints = result.keypoints\n",
    "                if keypoints is not None:\n",
    "                    keypoints_data = keypoints.data\n",
    "\n",
    "                    temp_person_info = []\n",
    "\n",
    "                    for person_keypoints in keypoints_data:\n",
    "                        keypoint_list = []\n",
    "                        row_data = {\"frame\": frame_count}\n",
    "\n",
    "                        for kp_idx, kp in enumerate(person_keypoints):\n",
    "                            x, y, conf = kp[0].item(), kp[1].item(), kp[2].item()\n",
    "                            if conf < 0.5:\n",
    "                                x, y = 0, 0\n",
    "                            keypoint_list.append((x, y, conf))\n",
    "                            row_data[f\"kp_{kp_idx}_x\"] = x\n",
    "                            row_data[f\"kp_{kp_idx}_y\"] = y\n",
    "                            row_data[f\"kp_{kp_idx}_conf\"] = conf\n",
    "                            cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "\n",
    "                        draw_lines(frame, keypoint_list, connections)\n",
    "\n",
    "                        if not keypoint_list:\n",
    "                            continue\n",
    "\n",
    "                        roi_x = keypoint_list[0][0]\n",
    "                        roi_idx = assign_roi_index(roi_x)\n",
    "                        roi_data = roi_lookup.get(roi_idx)\n",
    "\n",
    "                        if roi_data is None:\n",
    "                            print(f\"⚠️ No ROI config for roi_idx {roi_idx}, skipping.\")\n",
    "                            continue\n",
    "\n",
    "                        cv2.putText(frame, f\"ROI: {roi_idx}\", (int(roi_x), 50 + 30 * roi_idx), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                        \n",
    "                        row_data[\"desk_no\"] = roi_idx\n",
    "                        row_data[\"position\"] = roi_data[\"position\"]\n",
    "                        temp_person_info.append((roi_idx, row_data))\n",
    "\n",
    "                    temp_person_info.sort(key=lambda x: x[0])\n",
    "                    for new_idx, (_, row) in enumerate(temp_person_info):\n",
    "                        row[\"person_idx\"] = new_idx\n",
    "                        person_info_list.append(row)\n",
    "\n",
    "            all_frames_data.append((frame.copy(), person_info_list))\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        max_persons = max(len(info) for _, info in all_frames_data)\n",
    "        print(max_persons)\n",
    "\n",
    "        frame_hand_labels = {}\n",
    "        auto_labels = {}\n",
    "        for person_idx in range(max_persons):\n",
    "            roi_idx = row_data[\"desk_no\"]\n",
    "            print(f\"\\n\\u25ba Now annotating for Person #{roi_idx} of video {video_name}across all frames.\")\n",
    "\n",
    "            for frame_num, (frame, person_list) in enumerate(all_frames_data):\n",
    "                if person_idx >= len(person_list):\n",
    "                    continue\n",
    "                row_data = person_list[person_idx]\n",
    "                frame_to_show = frame.copy()\n",
    "                save_frame = frame_to_show.copy()\n",
    "\n",
    "                cv2.imshow(\"frame\", frame_to_show)\n",
    "                cv2.waitKey(1)\n",
    "\n",
    "                # ---- CHANGED: auto-assign hand_in_pocket = \"0\" (no prompt) ----\n",
    "                hand_in_pocket = \"0\"\n",
    "\n",
    "                row_data[\"hand_in_pocket\"] = hand_in_pocket\n",
    "                csv_writer.writerow(row_data)\n",
    "\n",
    "        print(f\"Annotation completed and saved {video_name} CSV.\")\n",
    "\n",
    "        new_video_path = os.path.join(input_dir, video_name + \".mp4\")\n",
    "\n",
    "        try:\n",
    "            # Ensure the destination name doesn't block us\n",
    "            if os.path.exists(new_video_path):\n",
    "                os.remove(new_video_path)\n",
    "\n",
    "            # Copy the processed source video (video_path) to the new name\n",
    "            shutil.copy2(video_path, new_video_path)\n",
    "            print(f\"Copied processed video to: {new_video_path}\")\n",
    "\n",
    "            # Optional quick sanity check: same size after copy\n",
    "            try:\n",
    "                if os.path.getsize(video_path) != os.path.getsize(new_video_path):\n",
    "                    print(\"⚠️ Warning: copied file size differs from source.\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Now delete the original file\n",
    "            if os.path.exists(video_path):\n",
    "                os.remove(video_path)\n",
    "                print(f\"Deleted original video: {video_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Video copy/overwrite/delete failed: {e}\")\n",
    "\n",
    "    csv_file.close()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8661c3",
   "metadata": {},
   "source": [
    "### Balanced TP csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f177ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tkinter import Tk, filedialog, Frame\n",
    "from pandastable import Table\n",
    "\n",
    "# Paths\n",
    "input_folder = \"C:/wajahat/hand_in_pocket/dataset/split_keypoint\"   \n",
    "output_folder = \"C:/wajahat/hand_in_pocket/dataset/training2/balanced/old_hp\" \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(input_folder, csv_file)\n",
    "    print(f\"\\nOpening {csv_file}...\\n\")\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    root = Tk()\n",
    "    root.title(f\"Editing {csv_file} - Close window when done\")\n",
    "\n",
    "    frame = Frame(root)\n",
    "    frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "    table = Table(frame, dataframe=df, showtoolbar=True, showstatusbar=True)\n",
    "    table.show()\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "    updated_df = table.model.df\n",
    "\n",
    "    save_path = os.path.join(output_folder, csv_file)\n",
    "    updated_df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved updated file to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b144a62",
   "metadata": {},
   "source": [
    "### Combined the single separate csvs into one csv\n",
    "set the window size, stride rate, and proportion of TP and TN combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d991cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Temporal features CSV saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "csv= \"fp_s1_t4\"\n",
    "input_folder = \"C:/Users/LT/Downloads/Final_balanced/FP_csv_room1\"\n",
    "output_dir = \"C:/wajahat/hand_in_pocket/dataset/training4/\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "output_file = f'{csv}_combine.csv'\n",
    "output_file = os.path.join(output_dir, output_file)\n",
    "\n",
    "window_size = 5  # Size of the rolling window\n",
    "stride = 1\n",
    "target_column = 'hand_in_pocket'\n",
    "\n",
    "columns_to_drop = ['person_idx']\n",
    "meta_columns = ['frame','desk_no']\n",
    "special_column = 'position'\n",
    "\n",
    "\n",
    "all_temporal_rows= []\n",
    "feature_cols = None\n",
    "\n",
    "csv_files = glob.glob(os.path.join(input_folder, '*.csv'))\n",
    "\n",
    "for file in csv_files:\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    if df.empty or len(df) < window_size:\n",
    "        print(f\"Skipping empty or too short file: {file}\")\n",
    "        continue\n",
    "\n",
    "    drop_cols = [col for col in df.columns if '_conf' in col or col.startswith(\"distance(\")]\n",
    "    df.drop(columns=drop_cols + columns_to_drop, inplace=True, errors=\"ignore\")\n",
    "\n",
    "    if feature_cols is None:\n",
    "        feature_cols = [col for col in df.columns \n",
    "                        if col not in meta_columns + [special_column, target_column]]\n",
    "        assert len(feature_cols) * window_size > 0 \n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "\n",
    "    for desk_no, desk_group in df.groupby(\"desk_no\"):\n",
    "        desk_group = desk_group.reset_index(drop=True)\n",
    "\n",
    "        if len(desk_group) < window_size:\n",
    "            print(f\"skipping desk {desk_no} in {file_name} due to less rows\")\n",
    "            continue\n",
    "\n",
    "        for i in range(0, len(desk_group) - window_size + 1, stride):\n",
    "            window = desk_group.iloc[i:i + window_size]\n",
    "\n",
    "            if len(window) < window_size:\n",
    "                continue\n",
    "\n",
    "            feature = window[feature_cols].values.flatten()\n",
    "\n",
    "            frame_val = window[meta_columns[0]].iloc[0]\n",
    "            desk_val = window[meta_columns[1]].iloc[0]\n",
    "\n",
    "            position_val = window[special_column].iloc[0] if special_column in window.columns else None\n",
    "\n",
    "            labels_counts = window[target_column].value_counts()\n",
    "            label = 1 if labels_counts.get(1,0) >= 1 else 0  # for the logic if there is 1 in the window, leabel is 1\n",
    "\n",
    "            all_temporal_rows.append([file_name, frame_val, desk_val] + feature.tolist() + [position_val, label])\n",
    "\n",
    "temporal_features_cols = [\n",
    "    f\"{col}_t{t}\" for t in range(window_size) for col in feature_cols\n",
    "]\n",
    "\n",
    "output_columns = ['source_file'] + meta_columns + temporal_features_cols + [special_column, target_column]\n",
    "\n",
    "temporal_df = pd.DataFrame(all_temporal_rows, columns=output_columns)\n",
    "temporal_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"✅ Temporal features CSV saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb6b10",
   "metadata": {},
   "source": [
    "Change the position values according to the json stored values\n",
    "update the position length accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d884449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Output saved to: C:/wajahat/hand_in_pocket/dataset/training4//tp_s2_t4_pos.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# === File paths ===\n",
    "csv = \"tp_s2_t4\"\n",
    "# input_csv = f\"C:/wajahat/hand_in_pocket/dataset/training2/window4/seq2/{csv}.csv\"\n",
    "input_csv = f\"C:/wajahat/hand_in_pocket/dataset/training4/{csv}_combine.csv\"\n",
    "output_dir = \"C:/wajahat/hand_in_pocket/dataset/training4/\"\n",
    "csv_name = f'{csv}_pos.csv'\n",
    "output_csv = f\"{output_dir}/{csv_name}\"\n",
    "# json_file = \"C:/wajahat/hand_in_pocket/qiyas_multicam.camera_final.json\"\n",
    "json_file = \"qiyas_multicam_2.camera.json\"\n",
    "\n",
    "position_length = 1\n",
    "\n",
    "# === Load data ===\n",
    "df = pd.read_csv(input_csv)\n",
    "with open(json_file, 'r') as f:\n",
    "    camera_data = json.load(f)\n",
    "\n",
    "# === Build camera map from JSON ===\n",
    "camera_map = {}\n",
    "for cam in camera_data:\n",
    "    if '_id' in cam:\n",
    "        match = re.search(r'camera_(\\d+)', cam['_id'])\n",
    "        if match:\n",
    "            cam_id = int(match.group(1))\n",
    "            camera_map[cam_id] = cam\n",
    "\n",
    "if position_length == 4:\n",
    "    # === Process rows for temporal feature ===\n",
    "    processed_rows = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            # Extract and validate position values\n",
    "            pos_vals = [row[f'position_t{i}'] for i in range(5)]\n",
    "            if len(set(pos_vals)) != 1:\n",
    "                # print(f\"Row {idx} skipped — Position values not uniform: {pos_vals}\")\n",
    "                continue  # Skip if position values differ\n",
    "\n",
    "            position_val = pos_vals[0]\n",
    "\n",
    "            # Extract camera number from source_file\n",
    "            source_file = row['source_file']\n",
    "            match = re.search(r'c(\\d+)_v\\d+', source_file)\n",
    "            if not match:\n",
    "                continue  # Skip if camera number not found\n",
    "\n",
    "            cam_id = int(match.group(1))\n",
    "            cam_info = camera_map.get(cam_id)\n",
    "            if not cam_info:\n",
    "                continue\n",
    "\n",
    "            # Look for matching position in camera JSON data\n",
    "            matched_entry = None\n",
    "            for entry in cam_info['data'].values():\n",
    "                if entry.get('position') == position_val:\n",
    "                    matched_entry = entry\n",
    "                    break\n",
    "\n",
    "            if not matched_entry or 'position_list' not in matched_entry:\n",
    "                continue\n",
    "\n",
    "            position_list = matched_entry['position_list']\n",
    "            if len(position_list) != 4:\n",
    "                continue  # Skip if not exactly 4 values\n",
    "\n",
    "            # Build new row with replaced columns\n",
    "            new_row = row.drop(labels=[f'position_t{i}' for i in range(5)]).to_dict()\n",
    "            new_row['position_a'], new_row['position_b'], new_row['position_c'], new_row['position_d'] = position_list\n",
    "            processed_rows.append(new_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping row {idx} due to error: {e}\")\n",
    "\n",
    "\n",
    "    # === processing rows for single position ===\n",
    "\n",
    "elif position_length == 1:\n",
    "    processed_rows = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            position_val = row['position']\n",
    "\n",
    "            source_file = row['source_file']\n",
    "            match = re.search(r'c(\\d+)_v\\d+', source_file)\n",
    "            # print(f\"match {match}\")\n",
    "            if not match:\n",
    "                # print(f\"match not found {match}\")\n",
    "                continue\n",
    "\n",
    "            cam_id = int(match.group(1))\n",
    "            cam_info = camera_map.get(cam_id)\n",
    "            # print(\"cam_info\", cam_info['data'].values())\n",
    "            if not cam_info:\n",
    "                # print(f\"cam info not found {cam_id}\")\n",
    "                continue\n",
    "\n",
    "            matched_entry = None\n",
    "            for entry in cam_info['data'].values():\n",
    "                if entry.get('position') == position_val:\n",
    "                    matched_entry = entry\n",
    "                    break\n",
    "\n",
    "            if not matched_entry or 'position_list' not in matched_entry:\n",
    "                # print(f\"matched entry not found {matched_entry}\")\n",
    "                continue\n",
    "\n",
    "            position_list = matched_entry['position_list']\n",
    "            if len(position_list) != 4:\n",
    "                # print(f\"position list not found {position_list}\")\n",
    "                continue\n",
    "\n",
    "            new_row = row.drop(labels=['position']).to_dict()\n",
    "            new_row['position_a'], new_row['position_b'], new_row['position_c'], new_row['position_d'] = position_list\n",
    "            processed_rows.append(new_row)\n",
    "            # print(\"processed_rows: \",processed_rows)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping row {idx} due to error: {e}\")\n",
    "\n",
    "    # === Final DataFrame and column ordering ===\n",
    "\n",
    "else:\n",
    "    print(\"Undefined position length\")\n",
    "    \n",
    "if processed_rows:\n",
    "    new_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "    new_df[\"camera\"] = new_df[\"source_file\"].str.extract(r'^(c\\d+)_')\n",
    "    new_df[\"video\"] = new_df[\"source_file\"].str.extract(r'_(v\\d+)')\n",
    "\n",
    "    # Drop source_file\n",
    "    if \"source_file\" in new_df.columns:\n",
    "        new_df = new_df.drop(columns=[\"source_file\"])\n",
    "\n",
    "    col_order = [\"camera\", \"video\"] + [c for c in new_df.columns if c not in [\"camera\", \"video\"]]\n",
    "    new_df = new_df[col_order]\n",
    "\n",
    "    # Reorder: insert position_a-d before hand_in_pocket\n",
    "    if 'hand_in_pocket' in new_df.columns:\n",
    "        cols = list(new_df.columns)\n",
    "        insert_at = cols.index('hand_in_pocket')\n",
    "        for col in ['position_a', 'position_b', 'position_c', 'position_d']:\n",
    "            if col in cols:\n",
    "                cols.remove(col)\n",
    "        cols = cols[:insert_at] + ['position_a', 'position_b', 'position_c', 'position_d'] + cols[insert_at:]\n",
    "        new_df = new_df[cols]\n",
    "\n",
    "    new_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n✅ Output saved to: {output_csv}\")\n",
    "else:\n",
    "    print(\"⚠️ No valid rows processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13447f0",
   "metadata": {},
   "source": [
    "### FInal CSV\n",
    "Rearrange the columns and combine all csvs into one for the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cffe524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined CSV saved to: C:/wajahat/hand_in_pocket/dataset/training4/itteration4_temp_norm_balanced.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "csv1 = \"C:/wajahat/hand_in_pocket/dataset/training3/old_hp_combine_pos.csv\"\n",
    "csv2 = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_combine_pos.csv\"\n",
    "csv3 = \"C:/wajahat/hand_in_pocket/dataset/training3/moiz_fp_combine_pos.csv\"\n",
    "csv4 = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_combine_pos.csv\"\n",
    "csv5 = \"C:/wajahat/hand_in_pocket/dataset/training3/fn_combine_pos.csv\"\n",
    "csv6 = \"C:/wajahat/hand_in_pocket/dataset/training3/mudassir_hp_combine_pos.csv\"\n",
    "csv7 = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_s1_w1_pos.csv\"\n",
    "csv8 = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_s1_w2_pos.csv\"\n",
    "csv9 = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_s2_w1_pos.csv\"\n",
    "csv10 = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_s2_w2_pos.csv\"\n",
    "csv11 = \"C:/wajahat/hand_in_pocket/dataset/training3/missing_s1_pos.csv\"\n",
    "csv12 = \"C:/wajahat/hand_in_pocket/dataset/training3/missing_s2_pos.csv\"\n",
    "csv13 = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_s1_w1_pos.csv\"\n",
    "csv14 = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_s1_w2_pos.csv\"\n",
    "csv15 = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_s2_w1_pos.csv\"\n",
    "csv16 = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_s2_w2_pos.csv\"\n",
    "csv17 = \"C:/wajahat/hand_in_pocket/dataset/training4/tp_s1_t4_pos.csv\"\n",
    "csv18 = \"C:/wajahat/hand_in_pocket/dataset/training4/fp_s1_t4_pos.csv\"\n",
    "csv19 = \"C:/wajahat/hand_in_pocket/dataset/training4/tp_s2_t4_pos.csv\"\n",
    "csv20 = \"C:/wajahat/hand_in_pocket/dataset/training4/fp_s2_t4_pos.csv\"\n",
    "\n",
    "# csv2 = \"C:/wajahat/hand_in_pocket/dataset/new_dataset/new_combined_sorted_balanced2.csv\"\n",
    "output_csv = \"C:/wajahat/hand_in_pocket/dataset/training4/itteration4_temp_norm_balanced.csv\"\n",
    "\n",
    "df1 = pd.read_csv(csv1)\n",
    "df2 = pd.read_csv(csv2)\n",
    "df3 = pd.read_csv(csv3)\n",
    "df4 = pd.read_csv(csv4)\n",
    "df5 = pd.read_csv(csv5)\n",
    "df6 = pd.read_csv(csv6)\n",
    "df7 = pd.read_csv(csv7)\n",
    "df8 = pd.read_csv(csv8)\n",
    "df9 = pd.read_csv(csv9)\n",
    "df10 = pd.read_csv(csv10)\n",
    "df11 = pd.read_csv(csv11)\n",
    "df12 = pd.read_csv(csv12)\n",
    "df13 = pd.read_csv(csv13)\n",
    "df14 = pd.read_csv(csv14)\n",
    "df15 = pd.read_csv(csv15)\n",
    "df16 = pd.read_csv(csv16)\n",
    "df17 = pd.read_csv(csv17)\n",
    "df18 = pd.read_csv(csv18)\n",
    "df19 = pd.read_csv(csv19)\n",
    "df20 = pd.read_csv(csv20)\n",
    "\n",
    "combined_df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15, df16, df17, df18, df19, df20], ignore_index=True)\n",
    "\n",
    "new_columns_order = [\"camera\",\t\"video\",\t\"frame\",\t\"desk_no\",\t\"kp_0_x_t0\",\t\"kp_0_x_t1\",\t\"kp_0_x_t2\",\t\"kp_0_x_t3\",\t\"kp_0_x_t4\",\t\"kp_0_y_t0\",\t\"kp_0_y_t1\",\n",
    "                     \t\"kp_0_y_t2\",\t\"kp_0_y_t3\",\t\"kp_0_y_t4\",\t\"kp_1_x_t0\",\t\"kp_1_x_t1\",\t\"kp_1_x_t2\",\t\"kp_1_x_t3\",\t\"kp_1_x_t4\",\n",
    "                        \t\"kp_1_y_t0\",\t\"kp_1_y_t1\",\t\"kp_1_y_t2\",\t\"kp_1_y_t3\",\t\"kp_1_y_t4\",\t\"kp_2_x_t0\",\t\"kp_2_x_t1\",\t\"kp_2_x_t2\",\n",
    "                            \t\"kp_2_x_t3\",\t\"kp_2_x_t4\",\t\"kp_2_y_t0\",\t\"kp_2_y_t1\",\t\"kp_2_y_t2\",\t\"kp_2_y_t3\",\t\"kp_2_y_t4\",\t\"kp_3_x_t0\",\n",
    "                                \"kp_3_x_t1\",\t\"kp_3_x_t2\",\t\"kp_3_x_t3\",\t\"kp_3_x_t4\",\t\"kp_3_y_t0\",\t\"kp_3_y_t1\",\t\"kp_3_y_t2\",\t\"kp_3_y_t3\",\n",
    "                            \"kp_3_y_t4\",\t\"kp_4_x_t0\",\t\"kp_4_x_t1\",\t\"kp_4_x_t2\",\t\"kp_4_x_t3\",\t\"kp_4_x_t4\",\t\"kp_4_y_t0\",\t\"kp_4_y_t1\",\t\n",
    "                        \"kp_4_y_t2\",\t\"kp_4_y_t3\",\t\"kp_4_y_t4\",\t\"kp_5_x_t0\",\t\"kp_5_x_t1\",\t\"kp_5_x_t2\",\t\"kp_5_x_t3\",\t\"kp_5_x_t4\",\t\n",
    "                    \"kp_5_y_t0\",\t\"kp_5_y_t1\",\t\"kp_5_y_t2\",\t\"kp_5_y_t3\",\t\"kp_5_y_t4\",\t\"kp_6_x_t0\",\t\"kp_6_x_t1\",\t\"kp_6_x_t2\",\t\n",
    "                \"kp_6_x_t3\",\t\"kp_6_x_t4\",\t\"kp_6_y_t0\",\t\"kp_6_y_t1\",\t\"kp_6_y_t2\",\t\"kp_6_y_t3\",\t\"kp_6_y_t4\",\t\"kp_7_x_t0\",\t\"kp_7_x_t1\",\n",
    "            \t\"kp_7_x_t2\",\t\"kp_7_x_t3\",\t\"kp_7_x_t4\",\t\"kp_7_y_t0\",\t\"kp_7_y_t1\",\t\"kp_7_y_t2\",\t\"kp_7_y_t3\",\t\"kp_7_y_t4\",\t\"kp_8_x_t0\",\n",
    "                \"kp_8_x_t1\",\t\"kp_8_x_t2\",\t\"kp_8_x_t3\",\t\"kp_8_x_t4\",\t\"kp_8_y_t0\",\t\"kp_8_y_t1\",\t\"kp_8_y_t2\",\t\"kp_8_y_t3\",\t\"kp_8_y_t4\",\t\n",
    "                \"kp_9_x_t0\",\t\"kp_9_x_t1\",\t\"kp_9_x_t2\",\t\"kp_9_x_t3\",\t\"kp_9_x_t4\",\t\"kp_9_y_t0\",\t\"kp_9_y_t1\",\t\"kp_9_y_t2\",\t\"kp_9_y_t3\",\n",
    "                    \t\"kp_9_y_t4\",\t\"position_a\",\t\"position_b\",\t\"position_c\",\t\"position_d\",\t\"hand_in_pocket\"]\n",
    "\n",
    "filtered_columns = [col for col in new_columns_order if col in combined_df.columns]\n",
    "combined_df = combined_df[filtered_columns]\n",
    "# combined_df = combined_df.astype(int)\n",
    "\n",
    "for col in combined_df.columns:\n",
    "    if 'x' in col.lower():\n",
    "        combined_df[col] = combined_df[col].astype(int) #for not normalized keypoint to convert them into numbers like 271,542\n",
    "        combined_df[col] = pd.to_numeric((combined_df[col] / 1280), errors='coerce')\n",
    "        combined_df[col] = combined_df[col].apply(lambda x: -1 if x == 0 else x)\n",
    "        combined_df[col] = combined_df[col].round(3) # for notmalized keypoints to convert them till 3 decimal places \n",
    "    elif 'y' in col.lower():\n",
    "        combined_df[col] = combined_df[col].astype(int) #for not normalized keypoint to convert them into numbers like 271,542\n",
    "        combined_df[col] = pd.to_numeric((combined_df[col] / 720), errors='coerce')\n",
    "        combined_df[col] = combined_df[col].apply(lambda x: -1 if x == 0 else x)\n",
    "        combined_df[col] = combined_df[col].round(3) # for notmalized keypoints to convert them till 3 decimal places \n",
    "    \n",
    "\n",
    "combined_df.to_csv(output_csv, index=False)\n",
    "# combined_df.to_csv(df, index=False)\n",
    "print(f\"✅ Combined CSV saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42c5b23",
   "metadata": {},
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc320d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in dataset: [0. 1.]\n",
      "Epoch 1/500 - Train Loss: 0.2541 - Val Loss: 0.2183 - Val Accuracy: 0.9195\n",
      "Epoch 2/500 - Train Loss: 0.2194 - Val Loss: 0.1883 - Val Accuracy: 0.9296\n",
      "Epoch 3/500 - Train Loss: 0.1981 - Val Loss: 0.1758 - Val Accuracy: 0.9319\n",
      "Epoch 4/500 - Train Loss: 0.1871 - Val Loss: 0.1676 - Val Accuracy: 0.9384\n",
      "Epoch 5/500 - Train Loss: 0.1805 - Val Loss: 0.1582 - Val Accuracy: 0.9401\n",
      "Epoch 6/500 - Train Loss: 0.1778 - Val Loss: 0.1591 - Val Accuracy: 0.9408\n",
      "Epoch 7/500 - Train Loss: 0.1746 - Val Loss: 0.1525 - Val Accuracy: 0.9403\n",
      "Epoch 8/500 - Train Loss: 0.1712 - Val Loss: 0.1484 - Val Accuracy: 0.9460\n",
      "Epoch 9/500 - Train Loss: 0.1701 - Val Loss: 0.1518 - Val Accuracy: 0.9451\n",
      "Epoch 10/500 - Train Loss: 0.1678 - Val Loss: 0.1489 - Val Accuracy: 0.9441\n",
      "Epoch 11/500 - Train Loss: 0.1645 - Val Loss: 0.1456 - Val Accuracy: 0.9469\n",
      "Epoch 12/500 - Train Loss: 0.1632 - Val Loss: 0.1465 - Val Accuracy: 0.9432\n",
      "Epoch 13/500 - Train Loss: 0.1629 - Val Loss: 0.1438 - Val Accuracy: 0.9459\n",
      "Epoch 14/500 - Train Loss: 0.1617 - Val Loss: 0.1394 - Val Accuracy: 0.9487\n",
      "Epoch 15/500 - Train Loss: 0.1601 - Val Loss: 0.1407 - Val Accuracy: 0.9479\n",
      "Epoch 16/500 - Train Loss: 0.1596 - Val Loss: 0.1444 - Val Accuracy: 0.9468\n",
      "Epoch 17/500 - Train Loss: 0.1592 - Val Loss: 0.1408 - Val Accuracy: 0.9487\n",
      "Epoch 18/500 - Train Loss: 0.1573 - Val Loss: 0.1391 - Val Accuracy: 0.9477\n",
      "Epoch 19/500 - Train Loss: 0.1575 - Val Loss: 0.1426 - Val Accuracy: 0.9465\n",
      "Epoch 20/500 - Train Loss: 0.1573 - Val Loss: 0.1441 - Val Accuracy: 0.9463\n",
      "Epoch 21/500 - Train Loss: 0.1545 - Val Loss: 0.1324 - Val Accuracy: 0.9521\n",
      "Epoch 22/500 - Train Loss: 0.1540 - Val Loss: 0.1385 - Val Accuracy: 0.9494\n",
      "Epoch 23/500 - Train Loss: 0.1538 - Val Loss: 0.1323 - Val Accuracy: 0.9506\n",
      "Epoch 24/500 - Train Loss: 0.1522 - Val Loss: 0.1484 - Val Accuracy: 0.9412\n",
      "Epoch 25/500 - Train Loss: 0.1522 - Val Loss: 0.1343 - Val Accuracy: 0.9503\n",
      "Epoch 26/500 - Train Loss: 0.1508 - Val Loss: 0.1355 - Val Accuracy: 0.9491\n",
      "Epoch 27/500 - Train Loss: 0.1506 - Val Loss: 0.1449 - Val Accuracy: 0.9483\n",
      "Epoch 28/500 - Train Loss: 0.1496 - Val Loss: 0.1309 - Val Accuracy: 0.9522\n",
      "Epoch 29/500 - Train Loss: 0.1494 - Val Loss: 0.1408 - Val Accuracy: 0.9499\n",
      "Epoch 30/500 - Train Loss: 0.1497 - Val Loss: 0.1389 - Val Accuracy: 0.9502\n",
      "Epoch 31/500 - Train Loss: 0.1475 - Val Loss: 0.1310 - Val Accuracy: 0.9529\n",
      "Epoch 32/500 - Train Loss: 0.1485 - Val Loss: 0.1325 - Val Accuracy: 0.9513\n",
      "Epoch 33/500 - Train Loss: 0.1474 - Val Loss: 0.1276 - Val Accuracy: 0.9529\n",
      "Epoch 34/500 - Train Loss: 0.1460 - Val Loss: 0.1305 - Val Accuracy: 0.9504\n",
      "Epoch 35/500 - Train Loss: 0.1453 - Val Loss: 0.1300 - Val Accuracy: 0.9526\n",
      "Epoch 36/500 - Train Loss: 0.1446 - Val Loss: 0.1303 - Val Accuracy: 0.9523\n",
      "Epoch 37/500 - Train Loss: 0.1450 - Val Loss: 0.1250 - Val Accuracy: 0.9541\n",
      "Epoch 38/500 - Train Loss: 0.1460 - Val Loss: 0.1337 - Val Accuracy: 0.9513\n",
      "Epoch 39/500 - Train Loss: 0.1455 - Val Loss: 0.1280 - Val Accuracy: 0.9528\n",
      "Epoch 40/500 - Train Loss: 0.1437 - Val Loss: 0.1317 - Val Accuracy: 0.9506\n",
      "Epoch 41/500 - Train Loss: 0.1454 - Val Loss: 0.1304 - Val Accuracy: 0.9540\n",
      "Epoch 42/500 - Train Loss: 0.1439 - Val Loss: 0.1312 - Val Accuracy: 0.9522\n",
      "Epoch 43/500 - Train Loss: 0.1443 - Val Loss: 0.1282 - Val Accuracy: 0.9536\n",
      "Epoch 44/500 - Train Loss: 0.1431 - Val Loss: 0.1273 - Val Accuracy: 0.9547\n",
      "Epoch 45/500 - Train Loss: 0.1438 - Val Loss: 0.1359 - Val Accuracy: 0.9489\n",
      "Epoch 46/500 - Train Loss: 0.1408 - Val Loss: 0.1317 - Val Accuracy: 0.9496\n",
      "Epoch 47/500 - Train Loss: 0.1415 - Val Loss: 0.1216 - Val Accuracy: 0.9562\n",
      "Epoch 48/500 - Train Loss: 0.1404 - Val Loss: 0.1307 - Val Accuracy: 0.9524\n",
      "Epoch 49/500 - Train Loss: 0.1400 - Val Loss: 0.1218 - Val Accuracy: 0.9547\n",
      "Epoch 50/500 - Train Loss: 0.1409 - Val Loss: 0.1299 - Val Accuracy: 0.9531\n",
      "Epoch 51/500 - Train Loss: 0.1397 - Val Loss: 0.1214 - Val Accuracy: 0.9561\n",
      "Epoch 52/500 - Train Loss: 0.1401 - Val Loss: 0.1234 - Val Accuracy: 0.9562\n",
      "Epoch 53/500 - Train Loss: 0.1401 - Val Loss: 0.1225 - Val Accuracy: 0.9553\n",
      "Epoch 54/500 - Train Loss: 0.1403 - Val Loss: 0.1336 - Val Accuracy: 0.9510\n",
      "Epoch 55/500 - Train Loss: 0.1391 - Val Loss: 0.1228 - Val Accuracy: 0.9562\n",
      "Epoch 56/500 - Train Loss: 0.1389 - Val Loss: 0.1350 - Val Accuracy: 0.9516\n",
      "Epoch 57/500 - Train Loss: 0.1392 - Val Loss: 0.1277 - Val Accuracy: 0.9538\n",
      "Epoch 58/500 - Train Loss: 0.1382 - Val Loss: 0.1222 - Val Accuracy: 0.9569\n",
      "Epoch 59/500 - Train Loss: 0.1382 - Val Loss: 0.1238 - Val Accuracy: 0.9548\n",
      "Epoch 60/500 - Train Loss: 0.1381 - Val Loss: 0.1271 - Val Accuracy: 0.9529\n",
      "Epoch 61/500 - Train Loss: 0.1386 - Val Loss: 0.1247 - Val Accuracy: 0.9534\n",
      "Epoch 62/500 - Train Loss: 0.1371 - Val Loss: 0.1248 - Val Accuracy: 0.9529\n",
      "Epoch 63/500 - Train Loss: 0.1252 - Val Loss: 0.1153 - Val Accuracy: 0.9587\n",
      "Epoch 64/500 - Train Loss: 0.1212 - Val Loss: 0.1151 - Val Accuracy: 0.9590\n",
      "Epoch 65/500 - Train Loss: 0.1211 - Val Loss: 0.1137 - Val Accuracy: 0.9593\n",
      "Epoch 66/500 - Train Loss: 0.1193 - Val Loss: 0.1142 - Val Accuracy: 0.9596\n",
      "Epoch 67/500 - Train Loss: 0.1209 - Val Loss: 0.1144 - Val Accuracy: 0.9591\n",
      "Epoch 68/500 - Train Loss: 0.1206 - Val Loss: 0.1137 - Val Accuracy: 0.9595\n",
      "Epoch 69/500 - Train Loss: 0.1198 - Val Loss: 0.1120 - Val Accuracy: 0.9599\n",
      "Epoch 70/500 - Train Loss: 0.1195 - Val Loss: 0.1121 - Val Accuracy: 0.9602\n",
      "Epoch 71/500 - Train Loss: 0.1193 - Val Loss: 0.1125 - Val Accuracy: 0.9602\n",
      "Epoch 72/500 - Train Loss: 0.1204 - Val Loss: 0.1126 - Val Accuracy: 0.9605\n",
      "Epoch 73/500 - Train Loss: 0.1193 - Val Loss: 0.1125 - Val Accuracy: 0.9602\n",
      "Epoch 74/500 - Train Loss: 0.1204 - Val Loss: 0.1120 - Val Accuracy: 0.9601\n",
      "Epoch 75/500 - Train Loss: 0.1190 - Val Loss: 0.1116 - Val Accuracy: 0.9604\n",
      "Epoch 76/500 - Train Loss: 0.1190 - Val Loss: 0.1142 - Val Accuracy: 0.9591\n",
      "Epoch 77/500 - Train Loss: 0.1192 - Val Loss: 0.1123 - Val Accuracy: 0.9599\n",
      "Epoch 78/500 - Train Loss: 0.1195 - Val Loss: 0.1116 - Val Accuracy: 0.9605\n",
      "Epoch 79/500 - Train Loss: 0.1193 - Val Loss: 0.1134 - Val Accuracy: 0.9603\n",
      "Epoch 80/500 - Train Loss: 0.1183 - Val Loss: 0.1137 - Val Accuracy: 0.9602\n",
      "Epoch 81/500 - Train Loss: 0.1180 - Val Loss: 0.1119 - Val Accuracy: 0.9604\n",
      "Epoch 82/500 - Train Loss: 0.1179 - Val Loss: 0.1115 - Val Accuracy: 0.9605\n",
      "Epoch 83/500 - Train Loss: 0.1193 - Val Loss: 0.1122 - Val Accuracy: 0.9607\n",
      "Epoch 84/500 - Train Loss: 0.1185 - Val Loss: 0.1114 - Val Accuracy: 0.9610\n",
      "Epoch 85/500 - Train Loss: 0.1202 - Val Loss: 0.1107 - Val Accuracy: 0.9610\n",
      "Epoch 86/500 - Train Loss: 0.1189 - Val Loss: 0.1105 - Val Accuracy: 0.9610\n",
      "Epoch 87/500 - Train Loss: 0.1186 - Val Loss: 0.1119 - Val Accuracy: 0.9608\n",
      "Epoch 88/500 - Train Loss: 0.1188 - Val Loss: 0.1111 - Val Accuracy: 0.9606\n",
      "Epoch 89/500 - Train Loss: 0.1189 - Val Loss: 0.1109 - Val Accuracy: 0.9612\n",
      "Epoch 90/500 - Train Loss: 0.1173 - Val Loss: 0.1111 - Val Accuracy: 0.9612\n",
      "Epoch 91/500 - Train Loss: 0.1179 - Val Loss: 0.1102 - Val Accuracy: 0.9611\n",
      "Epoch 92/500 - Train Loss: 0.1165 - Val Loss: 0.1101 - Val Accuracy: 0.9615\n",
      "Epoch 93/500 - Train Loss: 0.1180 - Val Loss: 0.1109 - Val Accuracy: 0.9616\n",
      "Epoch 94/500 - Train Loss: 0.1189 - Val Loss: 0.1117 - Val Accuracy: 0.9610\n",
      "Epoch 95/500 - Train Loss: 0.1176 - Val Loss: 0.1111 - Val Accuracy: 0.9608\n",
      "Epoch 96/500 - Train Loss: 0.1161 - Val Loss: 0.1116 - Val Accuracy: 0.9614\n",
      "Epoch 97/500 - Train Loss: 0.1183 - Val Loss: 0.1116 - Val Accuracy: 0.9607\n",
      "Epoch 98/500 - Train Loss: 0.1174 - Val Loss: 0.1113 - Val Accuracy: 0.9617\n",
      "Epoch 99/500 - Train Loss: 0.1188 - Val Loss: 0.1106 - Val Accuracy: 0.9617\n",
      "Epoch 100/500 - Train Loss: 0.1160 - Val Loss: 0.1105 - Val Accuracy: 0.9620\n",
      "Epoch 101/500 - Train Loss: 0.1158 - Val Loss: 0.1116 - Val Accuracy: 0.9615\n",
      "Epoch 102/500 - Train Loss: 0.1177 - Val Loss: 0.1106 - Val Accuracy: 0.9613\n",
      "Epoch 103/500 - Train Loss: 0.1166 - Val Loss: 0.1113 - Val Accuracy: 0.9616\n",
      "Epoch 104/500 - Train Loss: 0.1159 - Val Loss: 0.1108 - Val Accuracy: 0.9615\n",
      "Epoch 105/500 - Train Loss: 0.1149 - Val Loss: 0.1105 - Val Accuracy: 0.9616\n",
      "Epoch 106/500 - Train Loss: 0.1145 - Val Loss: 0.1107 - Val Accuracy: 0.9619\n",
      "Epoch 107/500 - Train Loss: 0.1141 - Val Loss: 0.1105 - Val Accuracy: 0.9617\n",
      "Epoch 108/500 - Train Loss: 0.1157 - Val Loss: 0.1103 - Val Accuracy: 0.9617\n",
      "Epoch 109/500 - Train Loss: 0.1152 - Val Loss: 0.1102 - Val Accuracy: 0.9619\n",
      "Epoch 110/500 - Train Loss: 0.1145 - Val Loss: 0.1106 - Val Accuracy: 0.9616\n",
      "Epoch 111/500 - Train Loss: 0.1151 - Val Loss: 0.1105 - Val Accuracy: 0.9617\n",
      "Epoch 112/500 - Train Loss: 0.1154 - Val Loss: 0.1104 - Val Accuracy: 0.9617\n",
      "Epoch 113/500 - Train Loss: 0.1150 - Val Loss: 0.1106 - Val Accuracy: 0.9614\n",
      "Epoch 114/500 - Train Loss: 0.1155 - Val Loss: 0.1107 - Val Accuracy: 0.9615\n",
      "Epoch 115/500 - Train Loss: 0.1144 - Val Loss: 0.1106 - Val Accuracy: 0.9615\n",
      "Epoch 116/500 - Train Loss: 0.1142 - Val Loss: 0.1106 - Val Accuracy: 0.9615\n",
      "Epoch 117/500 - Train Loss: 0.1150 - Val Loss: 0.1106 - Val Accuracy: 0.9615\n",
      "Early stopping triggered.\n",
      "Training complete. Best model saved to rf_models/mlp_v4-c0.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# -------- Configuration --------\n",
    "INPUT_SIZE = 64\n",
    "# HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "PATIENCE = 25\n",
    "model_name = \"mlp_v4-c0\"\n",
    "label_column = 'hand_in_pocket'\n",
    "\n",
    "# -------- Load Dataset --------\n",
    "df = pd.read_csv(\"C:/wajahat/hand_in_pocket/dataset/training4/itteration4_temp_norm_balanced.csv\")\n",
    "df = df.drop(columns=['camera', 'video', 'frame', 'desk_no',\n",
    "                      'kp_0_x_t1', 'kp_0_x_t3', 'kp_0_y_t1', 'kp_0_y_t3',\n",
    "                        'kp_1_x_t1', 'kp_1_x_t3', 'kp_1_y_t1', 'kp_1_y_t3',\n",
    "                        'kp_2_x_t1', 'kp_2_x_t3', 'kp_2_y_t1', 'kp_2_y_t3',\n",
    "                        'kp_3_x_t1', 'kp_3_x_t3', 'kp_3_y_t1', 'kp_3_y_t3',\n",
    "                        'kp_4_x_t1', 'kp_4_x_t3', 'kp_4_y_t1', 'kp_4_y_t3',\n",
    "                        'kp_5_x_t1', 'kp_5_x_t3', 'kp_5_y_t1', 'kp_5_y_t3',\n",
    "                        'kp_6_x_t1', 'kp_6_x_t3', 'kp_6_y_t1', 'kp_6_y_t3',\n",
    "                        'kp_7_x_t1', 'kp_7_x_t3', 'kp_7_y_t1', 'kp_7_y_t3',\n",
    "                        'kp_8_x_t1', 'kp_8_x_t3', 'kp_8_y_t1', 'kp_8_y_t3',\n",
    "                        'kp_9_x_t1', 'kp_9_x_t3', 'kp_9_y_t1', 'kp_9_y_t3'])\n",
    "\n",
    "df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "df = df.apply(pd.to_numeric)\n",
    "df.fillna(-1, inplace=True)\n",
    "\n",
    "X = df.drop(columns=[label_column]).values.astype(np.float32)\n",
    "y = df[label_column].values.astype(np.float32)\n",
    "\n",
    "unique_vals = np.unique(y)\n",
    "print(\"Unique labels in dataset:\", unique_vals)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_dataset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# -------- MLP Model --------\n",
    "# Classifier\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = MLP(INPUT_SIZE)\n",
    "\n",
    "# -------- Training Setup --------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss() # classificiation loss funvtion\n",
    "# criterion = nn.MSELoss() # regression loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(\"rf_models\", exist_ok=True)\n",
    "\n",
    "# -------- Early Stopping --------\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_y in val_loader:\n",
    "            val_X, val_y = val_X.to(device), val_y.to(device).unsqueeze(1)\n",
    "            outputs = model(val_X)\n",
    "            loss = criterion(outputs, val_y)\n",
    "            val_loss += loss.item()\n",
    "            predictions = (torch.sigmoid(outputs) >= 0.5).float()\n",
    "            val_accuracy += (predictions == val_y).float().mean().item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_accuracy = val_accuracy / len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {avg_train_loss:.4f} - Val Loss: {avg_val_loss:.4f} - Val Accuracy: {avg_val_accuracy:.4f}\")\n",
    "\n",
    "    # Early stopping and model saving\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_loss': best_loss\n",
    "        }, f\"rf_models/{model_name}.pt\")\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "print(f\"Training complete. Best model saved to rf_models/{model_name}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
