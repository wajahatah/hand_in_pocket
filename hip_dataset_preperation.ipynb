{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60079be",
   "metadata": {},
   "source": [
    "### Annotation\n",
    "Annotate each video and save data in the csv and rename the videos also,\n",
    "Take input for each person hand in pocket and can also automate the annotation for one person if press a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3bedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The script is used to annotate hand in pocket videos and generating a csv file with the keypoints and distances values. \n",
    "It take camera number and video number as input and name the csv file to that number with camera number and video number as cN_vN.\"\"\"\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "roi_data_list = []\n",
    "frame_count = 0\n",
    "saved_TP_frames = set()\n",
    "\n",
    "\n",
    "def draw_lines(frame, keypoints, connections):\n",
    "    for start_idx, end_idx in connections:\n",
    "        if start_idx < len(keypoints) and end_idx < len(keypoints):\n",
    "            x1, y1, conf1 = keypoints[start_idx]\n",
    "            x2, y2, conf2 = keypoints[end_idx]\n",
    "            if conf1 > 0.5 and conf2 > 0.5:\n",
    "                cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n",
    "\n",
    "def assign_roi_index(x):\n",
    "    for roi in roi_data_list:\n",
    "        if roi[\"xmin\"] <= x < roi[\"xmax\"]:\n",
    "            return roi[\"desk\"]\n",
    "    return -1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = YOLO(\"C:/wajahat/hand_in_pocket/bestv8-1.pt\")\n",
    "    input_dir = \"C:/Users/LT/Downloads/TP_S2/TP_S2\"\n",
    "    # video_name = \"c2_v4\"\n",
    "    output_dir = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_s2_w1\"\n",
    "    # json_path = \"qiyas_multicam.camera_final.json\"\n",
    "    json_path = \"qiyas_multicam_2.camera.json\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    video_files = [f for f in os.listdir(input_dir) if f.endswith(\".mp4\")]\n",
    "    if not video_files:\n",
    "        print(\"No video files found in the input directory.\")\n",
    "        exit()\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        video_path = os.path.join(input_dir, video_file)\n",
    "        print(f\"Processing {video_name}...\")\n",
    "    \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open video.\")\n",
    "            exit()\n",
    "\n",
    "        frame_width = 1280\n",
    "        frame_height = 720\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error reading first frame.\")\n",
    "            exit()\n",
    "\n",
    "        frame = cv2.resize(frame, (1280, 720))\n",
    "        cv2.imshow(\"Select Camera View\", frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        with open(json_path, \"r\") as f:\n",
    "            camera_config = json.load(f)\n",
    "\n",
    "        skip_video = False\n",
    "        while True:\n",
    "            cam_id = input(\"Enter camera ID: \")\n",
    "            if cam_id.lower() == 's':\n",
    "                with open(f\"{output_dir}/video_skip.csv\", \"a\", newline='') as f:\n",
    "                    f.write(f\"skipped the video: {video_file} \\n\")\n",
    "                skip_video = True\n",
    "                cap.release()\n",
    "                cv2.destroyWindow(\"Select Camera View\")\n",
    "                break\n",
    "            camera_id_input = cam_id\n",
    "            video_num = input(\"Enter video num:\")\n",
    "            camera_id = f\"camera_{camera_id_input}\"\n",
    "            camera_data = next((cam for cam in camera_config if cam[\"_id\"] == camera_id), None)\n",
    "            if camera_data:\n",
    "                break\n",
    "            print(f\"Invalid camera ID: {camera_id}. Please try again.\")\n",
    "\n",
    "        if skip_video:\n",
    "            continue\n",
    "\n",
    "        cv2.destroyWindow(\"Select Camera View\")\n",
    "\n",
    "        roi_data_list = list(camera_data[\"data\"].values())\n",
    "        roi_lookup = {roi[\"desk\"]: roi for roi in roi_data_list}\n",
    "\n",
    "        connections = [\n",
    "            (0, 1), (0, 2), (0, 3),\n",
    "            (1, 4), (1, 7),\n",
    "            (4, 5), (5, 6),\n",
    "            (7, 8), (8, 9)\n",
    "        ]\n",
    "        video_name = f\"c{camera_id_input}_v{video_num}\"\n",
    "        csv_filename = os.path.join(output_dir, video_name + \".csv\")\n",
    "\n",
    "        keypoint_headers = [f\"kp_{i}_x\" for i in range(10)] + [f\"kp_{i}_y\" for i in range(10)] + [f\"kp_{i}_conf\" for i in range(10)]\n",
    "        headers = [\"frame\", \"person_idx\", \"position\", \"desk_no\"] + keypoint_headers + [\"hand_in_pocket\"]\n",
    "\n",
    "        csv_file = open(csv_filename, \"w\", newline=\"\")\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "        csv_writer.writeheader()\n",
    "\n",
    "        all_frames_data = []\n",
    "        frame_count = 0\n",
    "        processed_videos= []\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, (1280, 720))\n",
    "            results = model(frame, verbose=False)\n",
    "            person_info_list = []\n",
    "\n",
    "            for result in results:\n",
    "                keypoints = result.keypoints\n",
    "                if keypoints is not None:\n",
    "                    keypoints_data = keypoints.data\n",
    "\n",
    "                    temp_person_info = []\n",
    "\n",
    "                    for person_keypoints in keypoints_data:\n",
    "                        keypoint_list = []\n",
    "                        row_data = {\"frame\": frame_count}\n",
    "\n",
    "                        for kp_idx, kp in enumerate(person_keypoints):\n",
    "                            x, y, conf = kp[0].item(), kp[1].item(), kp[2].item()\n",
    "                            if conf < 0.5:\n",
    "                                x, y = 0, 0\n",
    "                            keypoint_list.append((x, y, conf))\n",
    "                            row_data[f\"kp_{kp_idx}_x\"] = x\n",
    "                            row_data[f\"kp_{kp_idx}_y\"] = y\n",
    "                            row_data[f\"kp_{kp_idx}_conf\"] = conf\n",
    "                            if conf > 0.5:\n",
    "                                cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "\n",
    "                                draw_lines(frame, keypoint_list, connections)\n",
    "\n",
    "                        if not keypoint_list:\n",
    "                            continue\n",
    "\n",
    "                        roi_x = keypoint_list[0][0]\n",
    "                        roi_idx = assign_roi_index(roi_x)\n",
    "                        roi_data = roi_lookup.get(roi_idx)\n",
    "\n",
    "                        if roi_data is None:\n",
    "                            print(f\"⚠️ No ROI config for roi_idx {roi_idx}, skipping.\")\n",
    "                            continue\n",
    "\n",
    "                        cv2.putText(frame, f\"ROI: {roi_idx}\", (int(roi_x), 50 + 30 * roi_idx), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                        \n",
    "                        row_data[\"desk_no\"] = roi_idx\n",
    "                        row_data[\"position\"] = roi_data[\"position\"]\n",
    "\n",
    "                        temp_person_info.append((roi_idx, row_data))\n",
    "\n",
    "\n",
    "                    # Remap person_idx based on sorted roi\n",
    "                    temp_person_info.sort(key=lambda x: x[0])\n",
    "                    for new_idx, (_, row) in enumerate(temp_person_info):\n",
    "                        row[\"person_idx\"] = new_idx\n",
    "                        person_info_list.append(row)\n",
    "\n",
    "            all_frames_data.append((frame.copy(), person_info_list))\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        # Rearranged annotation loop by person across all frames\n",
    "        max_persons = max(len(info) for _, info in all_frames_data)\n",
    "        print(max_persons)\n",
    "\n",
    "        frame_hand_labels = {}\n",
    "        auto_labels = {}\n",
    "        for person_idx in range(max_persons):\n",
    "            print(f\"\\n\\u25ba Now annotating for Person #{roi_idx} of video {video_name}across all frames.\")\n",
    "\n",
    "            for frame_num, (frame, person_list) in enumerate(all_frames_data):\n",
    "                if person_idx >= len(person_list):\n",
    "                    continue\n",
    "                row_data = person_list[person_idx]\n",
    "                frame_to_show = frame.copy()\n",
    "                save_frame = frame_to_show.copy()\n",
    "\n",
    "                cv2.imshow(\"frame\", frame_to_show)\n",
    "                cv2.waitKey(1)\n",
    "\n",
    "                roi_idx = row_data[\"desk_no\"]\n",
    "                position = row_data[\"position\"]\n",
    "                prompt = f\"Frame {frame_num} | ROI {roi_idx} (Position: {position}): Enter hand_in_pocket (0 or 1) [Default: 0]: \"\n",
    "\n",
    "                if roi_idx in auto_labels:\n",
    "                    hand_in_pocket = auto_labels[roi_idx]\n",
    "                    print(f\"Auto label applird: ROI {roi_idx} -> {hand_in_pocket}\")\n",
    "                \n",
    "                else:\n",
    "                    while True:\n",
    "                        hand_in_pocket = input(prompt).strip()\n",
    "                        if hand_in_pocket.lower() == \"a\":\n",
    "                            value = input(f\"Enter value for ROI {roi_idx} (0 or 1): \").strip()\n",
    "                            if value not in [\"0\", \"1\"]:\n",
    "                                print(\"❌ Invalid value. Please enter 0 or 1.\")\n",
    "                                continue\n",
    "                            auto_labels[roi_idx] = value\n",
    "                            hand_in_pocket = value\n",
    "                            print(f\"Auto label set: ROI {roi_idx} -> {hand_in_pocket}\")\n",
    "                            break\n",
    "\n",
    "                        elif hand_in_pocket in [\"\",\"0\",\"1\"]:\n",
    "                            hand_in_pocket = hand_in_pocket or \"0\"\n",
    "                            break\n",
    "\n",
    "                        else:\n",
    "                            print(\"❌ Invalid input. Please enter 0 or 1 or press Enter for default 0.\")\n",
    "\n",
    "                row_data[\"hand_in_pocket\"] = hand_in_pocket\n",
    "                csv_writer.writerow(row_data)\n",
    "            \n",
    "        new_video_path = os.path.join(input_dir, video_name + \".mp4\")\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(new_video_path):\n",
    "                os.remove(new_video_path)\n",
    "\n",
    "            shutil.copy2(video_path, new_video_path)\n",
    "            print(f\"Copied processed video to: {new_video_path}\")\n",
    "\n",
    "            try:\n",
    "                if os.path.getsize(video_path) != os.path.getsize(new_video_path):\n",
    "                    print(\"⚠️ Warning: copied file size differs from source.\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            if os.path.exists(video_path):\n",
    "                os.remove(video_path)\n",
    "                print(f\"Deleted original video: {video_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Video copy/overwrite/delete failed: {e}\")\n",
    "\n",
    "    csv_file.close()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be27de1b",
   "metadata": {},
   "source": [
    "### FP Annotation\n",
    "Annotation of FP videos to assign automatically all data to 0, just need to enter the video num and it will create csv and rename the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# Global variable to hold loaded ROI data\n",
    "roi_data_list = []\n",
    "frame_count = 0\n",
    "saved_TP_frames = set()\n",
    "\n",
    "\n",
    "def draw_lines(frame, keypoints, connections):\n",
    "    for start_idx, end_idx in connections:\n",
    "        if start_idx < len(keypoints) and end_idx < len(keypoints):\n",
    "            x1, y1, conf1 = keypoints[start_idx]\n",
    "            x2, y2, conf2 = keypoints[end_idx]\n",
    "            if conf1 > 0.5 and conf2 > 0.5:\n",
    "                cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n",
    "\n",
    "def assign_roi_index(x):\n",
    "    for roi in roi_data_list:\n",
    "        if roi[\"xmin\"] <= x < roi[\"xmax\"]:\n",
    "            return roi[\"desk\"]\n",
    "    return -1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = YOLO(\"C:/wajahat/hand_in_pocket/bestv8-1.pt\")\n",
    "    input_dir = \"C:/Users/LT/Downloads/fp/fp\"\n",
    "    # video_name = \"c2_v4\"\n",
    "    output_dir = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_s2_w1\"\n",
    "    # json_path = \"qiyas_multicam.camera_final.json\"\n",
    "    json_path = \"qiyas_multicam_2.camera.json\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    video_files = [f for f in os.listdir(input_dir) if f.endswith(\".mp4\")]\n",
    "    if not video_files:\n",
    "        print(\"No video files found in the input directory.\")\n",
    "        exit()\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        video_path = os.path.join(input_dir, video_file)\n",
    "        print(f\"Processing {video_name}...\")\n",
    "    \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open video.\")\n",
    "            exit()\n",
    "\n",
    "        frame_width = 1280\n",
    "        frame_height = 720\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_height)\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error reading first frame.\")\n",
    "            exit()\n",
    "\n",
    "        frame = cv2.resize(frame, (1280, 720))\n",
    "        cv2.imshow(\"Select Camera View\", frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        with open(json_path, \"r\") as f:\n",
    "            camera_config = json.load(f)\n",
    "\n",
    "        while True:\n",
    "            camera_id_input = input(\"Enter camera ID for this video (e.g., camera_1): \")\n",
    "            video_num = input(\"Enter video name:\")\n",
    "            camera_id = f\"camera_{camera_id_input}\"\n",
    "            camera_data = next((cam for cam in camera_config if cam[\"_id\"] == camera_id), None)\n",
    "            if camera_data:\n",
    "                break\n",
    "            print(f\"Invalid camera ID: {camera_id}. Please try again.\")\n",
    "\n",
    "        cv2.destroyWindow(\"Select Camera View\")\n",
    "\n",
    "        roi_data_list = list(camera_data[\"data\"].values())\n",
    "        roi_lookup = {roi[\"desk\"]: roi for roi in roi_data_list}\n",
    "\n",
    "        connections = [\n",
    "            (0, 1), (0, 2), (0, 3),\n",
    "            (1, 4), (1, 7),\n",
    "            (4, 5), (5, 6),\n",
    "            (7, 8), (8, 9)\n",
    "        ]\n",
    "        video_name = f\"c{camera_id_input}_v{video_num}\"\n",
    "        csv_filename = os.path.join(output_dir, video_name + \".csv\")\n",
    "\n",
    "        keypoint_headers = [f\"kp_{i}_x\" for i in range(10)] + [f\"kp_{i}_y\" for i in range(10)] + [f\"kp_{i}_conf\" for i in range(10)]\n",
    "        headers = [\"frame\", \"person_idx\", \"position\", \"desk_no\"] + keypoint_headers + [\"hand_in_pocket\"]\n",
    "\n",
    "        csv_file = open(csv_filename, \"w\", newline=\"\")\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
    "        csv_writer.writeheader()\n",
    "\n",
    "        all_frames_data = []\n",
    "        frame_count = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, (1280, 720))\n",
    "            save_frame = frame.copy()\n",
    "            results = model(frame, verbose=False)\n",
    "            person_info_list = []\n",
    "\n",
    "            for result in results:\n",
    "                keypoints = result.keypoints\n",
    "                if keypoints is not None:\n",
    "                    keypoints_data = keypoints.data\n",
    "\n",
    "                    temp_person_info = []\n",
    "\n",
    "                    for person_keypoints in keypoints_data:\n",
    "                        keypoint_list = []\n",
    "                        row_data = {\"frame\": frame_count}\n",
    "\n",
    "                        for kp_idx, kp in enumerate(person_keypoints):\n",
    "                            x, y, conf = kp[0].item(), kp[1].item(), kp[2].item()\n",
    "                            if conf < 0.5:\n",
    "                                x, y = 0, 0\n",
    "                            keypoint_list.append((x, y, conf))\n",
    "                            row_data[f\"kp_{kp_idx}_x\"] = x\n",
    "                            row_data[f\"kp_{kp_idx}_y\"] = y\n",
    "                            row_data[f\"kp_{kp_idx}_conf\"] = conf\n",
    "                            cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "\n",
    "                        draw_lines(frame, keypoint_list, connections)\n",
    "\n",
    "                        if not keypoint_list:\n",
    "                            continue\n",
    "\n",
    "                        roi_x = keypoint_list[0][0]\n",
    "                        roi_idx = assign_roi_index(roi_x)\n",
    "                        roi_data = roi_lookup.get(roi_idx)\n",
    "\n",
    "                        if roi_data is None:\n",
    "                            print(f\"⚠️ No ROI config for roi_idx {roi_idx}, skipping.\")\n",
    "                            continue\n",
    "\n",
    "                        cv2.putText(frame, f\"ROI: {roi_idx}\", (int(roi_x), 50 + 30 * roi_idx), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                        \n",
    "                        row_data[\"desk_no\"] = roi_idx\n",
    "                        row_data[\"position\"] = roi_data[\"position\"]\n",
    "                        temp_person_info.append((roi_idx, row_data))\n",
    "\n",
    "                    temp_person_info.sort(key=lambda x: x[0])\n",
    "                    for new_idx, (_, row) in enumerate(temp_person_info):\n",
    "                        row[\"person_idx\"] = new_idx\n",
    "                        person_info_list.append(row)\n",
    "\n",
    "            all_frames_data.append((frame.copy(), person_info_list))\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        max_persons = max(len(info) for _, info in all_frames_data)\n",
    "        print(max_persons)\n",
    "\n",
    "        frame_hand_labels = {}\n",
    "        auto_labels = {}\n",
    "        for person_idx in range(max_persons):\n",
    "            roi_idx = row_data[\"desk_no\"]\n",
    "            print(f\"\\n\\u25ba Now annotating for Person #{roi_idx} of video {video_name}across all frames.\")\n",
    "\n",
    "            for frame_num, (frame, person_list) in enumerate(all_frames_data):\n",
    "                if person_idx >= len(person_list):\n",
    "                    continue\n",
    "                row_data = person_list[person_idx]\n",
    "                frame_to_show = frame.copy()\n",
    "                save_frame = frame_to_show.copy()\n",
    "\n",
    "                cv2.imshow(\"frame\", frame_to_show)\n",
    "                cv2.waitKey(1)\n",
    "\n",
    "                # ---- CHANGED: auto-assign hand_in_pocket = \"0\" (no prompt) ----\n",
    "                hand_in_pocket = \"0\"\n",
    "\n",
    "                row_data[\"hand_in_pocket\"] = hand_in_pocket\n",
    "                csv_writer.writerow(row_data)\n",
    "\n",
    "        print(f\"Annotation completed and saved {video_name} CSV.\")\n",
    "\n",
    "        new_video_path = os.path.join(input_dir, video_name + \".mp4\")\n",
    "\n",
    "        try:\n",
    "            # Ensure the destination name doesn't block us\n",
    "            if os.path.exists(new_video_path):\n",
    "                os.remove(new_video_path)\n",
    "\n",
    "            # Copy the processed source video (video_path) to the new name\n",
    "            shutil.copy2(video_path, new_video_path)\n",
    "            print(f\"Copied processed video to: {new_video_path}\")\n",
    "\n",
    "            # Optional quick sanity check: same size after copy\n",
    "            try:\n",
    "                if os.path.getsize(video_path) != os.path.getsize(new_video_path):\n",
    "                    print(\"⚠️ Warning: copied file size differs from source.\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # Now delete the original file\n",
    "            if os.path.exists(video_path):\n",
    "                os.remove(video_path)\n",
    "                print(f\"Deleted original video: {video_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Video copy/overwrite/delete failed: {e}\")\n",
    "\n",
    "    csv_file.close()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8661c3",
   "metadata": {},
   "source": [
    "### Balanced TP csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f177ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tkinter import Tk, filedialog, Frame\n",
    "from pandastable import Table\n",
    "\n",
    "# Paths\n",
    "input_folder = \"C:/wajahat/hand_in_pocket/dataset/split_keypoint\"   \n",
    "output_folder = \"C:/wajahat/hand_in_pocket/dataset/training2/balanced/old_hp\" \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(input_folder, csv_file)\n",
    "    print(f\"\\nOpening {csv_file}...\\n\")\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    root = Tk()\n",
    "    root.title(f\"Editing {csv_file} - Close window when done\")\n",
    "\n",
    "    frame = Frame(root)\n",
    "    frame.pack(fill=\"both\", expand=True)\n",
    "\n",
    "    table = Table(frame, dataframe=df, showtoolbar=True, showstatusbar=True)\n",
    "    table.show()\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "    updated_df = table.model.df\n",
    "\n",
    "    save_path = os.path.join(output_folder, csv_file)\n",
    "    updated_df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved updated file to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b144a62",
   "metadata": {},
   "source": [
    "### Combined the single separate csvs into one csv\n",
    "set the window size, stride rate, and proportion of TP and TN combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d991cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "csv= \"tp_s1_w1\"\n",
    "input_folder = \"C:/Users/LT/Downloads/Final_balanced/TP_csv_room1\"\n",
    "output_dir = \"C:/wajahat/hand_in_pocket/dataset/training4/\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "output_file = f'{csv}_combine.csv'\n",
    "output_file = os.path.join(output_dir, output_file)\n",
    "\n",
    "window_size = 5  # Size of the rolling window\n",
    "stride = 1\n",
    "target_column = 'hand_in_pocket'\n",
    "\n",
    "columns_to_drop = ['person_idx']\n",
    "meta_columns = ['frame','desk_no']\n",
    "special_column = 'position'\n",
    "\n",
    "\n",
    "all_temporal_rows= []\n",
    "feature_cols = None\n",
    "\n",
    "csv_files = glob.glob(os.path.join(input_folder, '*.csv'))\n",
    "\n",
    "for file in csv_files:\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    if df.empty or len(df) < window_size:\n",
    "        print(f\"Skipping empty or too short file: {file}\")\n",
    "        continue\n",
    "\n",
    "    drop_cols = [col for col in df.columns if '_conf' in col or col.startswith(\"distance(\")]\n",
    "    df.drop(columns=drop_cols + columns_to_drop, inplace=True, errors=\"ignore\")\n",
    "\n",
    "    if feature_cols is None:\n",
    "        feature_cols = [col for col in df.columns \n",
    "                        if col not in meta_columns + [special_column, target_column]]\n",
    "        assert len(feature_cols) * window_size > 0 \n",
    "\n",
    "    file_name = os.path.basename(file)\n",
    "\n",
    "    for desk_no, desk_group in df.groupby(\"desk_no\"):\n",
    "        desk_group = desk_group.reset_index(drop=True)\n",
    "\n",
    "        if len(desk_group) < window_size:\n",
    "            print(f\"skipping desk {desk_no} in {file_name} due to less rows\")\n",
    "            continue\n",
    "\n",
    "        for i in range(0, len(desk_group) - window_size + 1, stride):\n",
    "            window = desk_group.iloc[i:i + window_size]\n",
    "\n",
    "            if len(window) < window_size:\n",
    "                continue\n",
    "\n",
    "            feature = window[feature_cols].values.flatten()\n",
    "\n",
    "            frame_val = window[meta_columns[0]].iloc[0]\n",
    "            desk_val = window[meta_columns[1]].iloc[0]\n",
    "\n",
    "            position_val = window[special_column].iloc[0] if special_column in window.columns else None\n",
    "\n",
    "            labels_counts = window[target_column].value_counts()\n",
    "            label = 1 if labels_counts.get(1,0) >= 1 else 0  # for the logic if there is 1 in the window, leabel is 1\n",
    "\n",
    "            all_temporal_rows.append([file_name, frame_val, desk_val] + feature.tolist() + [position_val, label])\n",
    "\n",
    "temporal_features_cols = [\n",
    "    f\"{col}_t{t}\" for t in range(window_size) for col in feature_cols\n",
    "]\n",
    "\n",
    "output_columns = ['source_file'] + meta_columns + temporal_features_cols + [special_column, target_column]\n",
    "\n",
    "temporal_df = pd.DataFrame(all_temporal_rows, columns=output_columns)\n",
    "temporal_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"✅ Temporal features CSV saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb6b10",
   "metadata": {},
   "source": [
    "Change the position values according to the json stored values\n",
    "update the position length accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d884449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# === File paths ===\n",
    "csv = \"tp_s1_w1\"\n",
    "# input_csv = f\"C:/wajahat/hand_in_pocket/dataset/training2/window4/seq2/{csv}.csv\"\n",
    "input_csv = f\"C:/wajahat/hand_in_pocket/dataset/training3/{csv}_combine.csv\"\n",
    "output_dir = \"C:/wajahat/hand_in_pocket/dataset/training3/\"\n",
    "csv_name = f'{csv}_pos.csv'\n",
    "output_csv = f\"{output_dir}/{csv_name}\"\n",
    "json_file = \"C:/wajahat/hand_in_pocket/qiyas_multicam.camera_final.json\"\n",
    "# json_file = \"qiyas_multicam_2.camera.json\"\n",
    "\n",
    "position_length = 1\n",
    "\n",
    "# === Load data ===\n",
    "df = pd.read_csv(input_csv)\n",
    "with open(json_file, 'r') as f:\n",
    "    camera_data = json.load(f)\n",
    "\n",
    "# === Build camera map from JSON ===\n",
    "camera_map = {}\n",
    "for cam in camera_data:\n",
    "    if '_id' in cam:\n",
    "        match = re.search(r'camera_(\\d+)', cam['_id'])\n",
    "        if match:\n",
    "            cam_id = int(match.group(1))\n",
    "            camera_map[cam_id] = cam\n",
    "\n",
    "if position_length == 4:\n",
    "    # === Process rows for temporal feature ===\n",
    "    processed_rows = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            # Extract and validate position values\n",
    "            pos_vals = [row[f'position_t{i}'] for i in range(5)]\n",
    "            if len(set(pos_vals)) != 1:\n",
    "                # print(f\"Row {idx} skipped — Position values not uniform: {pos_vals}\")\n",
    "                continue  # Skip if position values differ\n",
    "\n",
    "            position_val = pos_vals[0]\n",
    "\n",
    "            # Extract camera number from source_file\n",
    "            source_file = row['source_file']\n",
    "            match = re.search(r'c(\\d+)_v\\d+', source_file)\n",
    "            if not match:\n",
    "                continue  # Skip if camera number not found\n",
    "\n",
    "            cam_id = int(match.group(1))\n",
    "            cam_info = camera_map.get(cam_id)\n",
    "            if not cam_info:\n",
    "                continue\n",
    "\n",
    "            # Look for matching position in camera JSON data\n",
    "            matched_entry = None\n",
    "            for entry in cam_info['data'].values():\n",
    "                if entry.get('position') == position_val:\n",
    "                    matched_entry = entry\n",
    "                    break\n",
    "\n",
    "            if not matched_entry or 'position_list' not in matched_entry:\n",
    "                continue\n",
    "\n",
    "            position_list = matched_entry['position_list']\n",
    "            if len(position_list) != 4:\n",
    "                continue  # Skip if not exactly 4 values\n",
    "\n",
    "            # Build new row with replaced columns\n",
    "            new_row = row.drop(labels=[f'position_t{i}' for i in range(5)]).to_dict()\n",
    "            new_row['position_a'], new_row['position_b'], new_row['position_c'], new_row['position_d'] = position_list\n",
    "            processed_rows.append(new_row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping row {idx} due to error: {e}\")\n",
    "\n",
    "\n",
    "    # === processing rows for single position ===\n",
    "\n",
    "elif position_length == 1:\n",
    "    processed_rows = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            position_val = row['position']\n",
    "\n",
    "            source_file = row['source_file']\n",
    "            match = re.search(r'c(\\d+)_v\\d+', source_file)\n",
    "            # print(f\"match {match}\")\n",
    "            if not match:\n",
    "                # print(f\"match not found {match}\")\n",
    "                continue\n",
    "\n",
    "            cam_id = int(match.group(1))\n",
    "            cam_info = camera_map.get(cam_id)\n",
    "            # print(\"cam_info\", cam_info['data'].values())\n",
    "            if not cam_info:\n",
    "                # print(f\"cam info not found {cam_id}\")\n",
    "                continue\n",
    "\n",
    "            matched_entry = None\n",
    "            for entry in cam_info['data'].values():\n",
    "                if entry.get('position') == position_val:\n",
    "                    matched_entry = entry\n",
    "                    break\n",
    "\n",
    "            if not matched_entry or 'position_list' not in matched_entry:\n",
    "                # print(f\"matched entry not found {matched_entry}\")\n",
    "                continue\n",
    "\n",
    "            position_list = matched_entry['position_list']\n",
    "            if len(position_list) != 4:\n",
    "                # print(f\"position list not found {position_list}\")\n",
    "                continue\n",
    "\n",
    "            new_row = row.drop(labels=['position']).to_dict()\n",
    "            new_row['position_a'], new_row['position_b'], new_row['position_c'], new_row['position_d'] = position_list\n",
    "            processed_rows.append(new_row)\n",
    "            # print(\"processed_rows: \",processed_rows)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping row {idx} due to error: {e}\")\n",
    "\n",
    "    # === Final DataFrame and column ordering ===\n",
    "\n",
    "else:\n",
    "    print(\"Undefined position length\")\n",
    "    \n",
    "if processed_rows:\n",
    "    new_df = pd.DataFrame(processed_rows)\n",
    "\n",
    "    new_df[\"camera\"] = new_df[\"source_file\"].str.extract(r'^(c\\d+)_')\n",
    "    new_df[\"video\"] = new_df[\"source_file\"].str.extract(r'_(v\\d+)')\n",
    "\n",
    "    # Drop source_file\n",
    "    if \"source_file\" in new_df.columns:\n",
    "        new_df = new_df.drop(columns=[\"source_file\"])\n",
    "\n",
    "    col_order = [\"camera\", \"video\"] + [c for c in new_df.columns if c not in [\"camera\", \"video\"]]\n",
    "    new_df = new_df[col_order]\n",
    "\n",
    "    # Reorder: insert position_a-d before hand_in_pocket\n",
    "    if 'hand_in_pocket' in new_df.columns:\n",
    "        cols = list(new_df.columns)\n",
    "        insert_at = cols.index('hand_in_pocket')\n",
    "        for col in ['position_a', 'position_b', 'position_c', 'position_d']:\n",
    "            if col in cols:\n",
    "                cols.remove(col)\n",
    "        cols = cols[:insert_at] + ['position_a', 'position_b', 'position_c', 'position_d'] + cols[insert_at:]\n",
    "        new_df = new_df[cols]\n",
    "\n",
    "    new_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n✅ Output saved to: {output_csv}\")\n",
    "else:\n",
    "    print(\"⚠️ No valid rows processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13447f0",
   "metadata": {},
   "source": [
    "### FInal CSV\n",
    "Rearrange the columns and combine all csvs into one for the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cffe524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "csv1 = \"C:/wajahat/hand_in_pocket/dataset/training3/old_hp_combine_pos.csv\"\n",
    "csv2 = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_combine_pos.csv\"\n",
    "csv3 = \"C:/wajahat/hand_in_pocket/dataset/training3/moiz_fp_combine_pos.csv\"\n",
    "csv4 = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_combine_pos.csv\"\n",
    "csv5 = \"C:/wajahat/hand_in_pocket/dataset/training3/fn_combine_pos.csv\"\n",
    "csv6 = \"C:/wajahat/hand_in_pocket/dataset/training3/mudassir_hp_combine_pos.csv\"\n",
    "csv7 = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_s1_w1_pos.csv\"\n",
    "csv8 = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_s1_w2_pos.csv\"\n",
    "csv9 = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_s2_w1_pos.csv\"\n",
    "csv10 = \"C:/wajahat/hand_in_pocket/dataset/training3/fp_s2_w2_pos.csv\"\n",
    "csv11 = \"C:/wajahat/hand_in_pocket/dataset/training3/missing_s1_pos.csv\"\n",
    "csv12 = \"C:/wajahat/hand_in_pocket/dataset/training3/missing_s2_pos.csv\"\n",
    "csv13 = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_s1_w1_pos.csv\"\n",
    "csv14 = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_s1_w2_pos.csv\"\n",
    "csv15 = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_s2_w1_pos.csv\"\n",
    "csv16 = \"C:/wajahat/hand_in_pocket/dataset/training3/tp_s2_w2_pos.csv\"\n",
    "# csv17 =\n",
    "# csv18 =\n",
    "# csv19 =\n",
    "# csv20 =\n",
    "\n",
    "# csv2 = \"C:/wajahat/hand_in_pocket/dataset/new_dataset/new_combined_sorted_balanced2.csv\"\n",
    "output_csv = \"C:/wajahat/hand_in_pocket/dataset/training3/itteration3_temp_norm_balanced.csv\"\n",
    "\n",
    "df1 = pd.read_csv(csv1)\n",
    "df2 = pd.read_csv(csv2)\n",
    "df3 = pd.read_csv(csv3)\n",
    "df4 = pd.read_csv(csv4)\n",
    "df5 = pd.read_csv(csv5)\n",
    "df6 = pd.read_csv(csv6)\n",
    "df7 = pd.read_csv(csv7)\n",
    "df8 = pd.read_csv(csv8)\n",
    "df9 = pd.read_csv(csv9)\n",
    "df10 = pd.read_csv(csv10)\n",
    "df11 = pd.read_csv(csv11)\n",
    "df12 = pd.read_csv(csv12)\n",
    "df13 = pd.read_csv(csv13)\n",
    "df14 = pd.read_csv(csv14)\n",
    "df15 = pd.read_csv(csv15)\n",
    "df16 = pd.read_csv(csv16)\n",
    "# df17 = pd.read_csv(csv17)\n",
    "# df18 = pd.read_csv(csv18)\n",
    "# df19 = pd.read_csv(csv19)\n",
    "# df20 = pd.read_csv(csv20)\n",
    "# df = \"C:/Users/LT/Downloads/new_combined_temp_balanced.csv\"\n",
    "# df = \"C:/wajahat/hand_in_pocket/dataset/training2/new_combined_temp_balanced.csv\"\n",
    "# combined_df = pd.read_csv(df)\n",
    "# df = \"C:/wajahat/hand_in_pocket/dataset/training2/new_combined_temp_balanced_norm_without_seq2.csv\"\n",
    "combined_df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15, df16], ignore_index=True)\n",
    "\n",
    "new_columns_order = [\"camera\",\t\"video\",\t\"frame\",\t\"desk_no\",\t\"kp_0_x_t0\",\t\"kp_0_x_t1\",\t\"kp_0_x_t2\",\t\"kp_0_x_t3\",\t\"kp_0_x_t4\",\t\"kp_0_y_t0\",\t\"kp_0_y_t1\",\n",
    "                     \t\"kp_0_y_t2\",\t\"kp_0_y_t3\",\t\"kp_0_y_t4\",\t\"kp_1_x_t0\",\t\"kp_1_x_t1\",\t\"kp_1_x_t2\",\t\"kp_1_x_t3\",\t\"kp_1_x_t4\",\n",
    "                        \t\"kp_1_y_t0\",\t\"kp_1_y_t1\",\t\"kp_1_y_t2\",\t\"kp_1_y_t3\",\t\"kp_1_y_t4\",\t\"kp_2_x_t0\",\t\"kp_2_x_t1\",\t\"kp_2_x_t2\",\n",
    "                            \t\"kp_2_x_t3\",\t\"kp_2_x_t4\",\t\"kp_2_y_t0\",\t\"kp_2_y_t1\",\t\"kp_2_y_t2\",\t\"kp_2_y_t3\",\t\"kp_2_y_t4\",\t\"kp_3_x_t0\",\n",
    "                                \"kp_3_x_t1\",\t\"kp_3_x_t2\",\t\"kp_3_x_t3\",\t\"kp_3_x_t4\",\t\"kp_3_y_t0\",\t\"kp_3_y_t1\",\t\"kp_3_y_t2\",\t\"kp_3_y_t3\",\n",
    "                            \"kp_3_y_t4\",\t\"kp_4_x_t0\",\t\"kp_4_x_t1\",\t\"kp_4_x_t2\",\t\"kp_4_x_t3\",\t\"kp_4_x_t4\",\t\"kp_4_y_t0\",\t\"kp_4_y_t1\",\t\n",
    "                        \"kp_4_y_t2\",\t\"kp_4_y_t3\",\t\"kp_4_y_t4\",\t\"kp_5_x_t0\",\t\"kp_5_x_t1\",\t\"kp_5_x_t2\",\t\"kp_5_x_t3\",\t\"kp_5_x_t4\",\t\n",
    "                    \"kp_5_y_t0\",\t\"kp_5_y_t1\",\t\"kp_5_y_t2\",\t\"kp_5_y_t3\",\t\"kp_5_y_t4\",\t\"kp_6_x_t0\",\t\"kp_6_x_t1\",\t\"kp_6_x_t2\",\t\n",
    "                \"kp_6_x_t3\",\t\"kp_6_x_t4\",\t\"kp_6_y_t0\",\t\"kp_6_y_t1\",\t\"kp_6_y_t2\",\t\"kp_6_y_t3\",\t\"kp_6_y_t4\",\t\"kp_7_x_t0\",\t\"kp_7_x_t1\",\n",
    "            \t\"kp_7_x_t2\",\t\"kp_7_x_t3\",\t\"kp_7_x_t4\",\t\"kp_7_y_t0\",\t\"kp_7_y_t1\",\t\"kp_7_y_t2\",\t\"kp_7_y_t3\",\t\"kp_7_y_t4\",\t\"kp_8_x_t0\",\n",
    "                \"kp_8_x_t1\",\t\"kp_8_x_t2\",\t\"kp_8_x_t3\",\t\"kp_8_x_t4\",\t\"kp_8_y_t0\",\t\"kp_8_y_t1\",\t\"kp_8_y_t2\",\t\"kp_8_y_t3\",\t\"kp_8_y_t4\",\t\n",
    "                \"kp_9_x_t0\",\t\"kp_9_x_t1\",\t\"kp_9_x_t2\",\t\"kp_9_x_t3\",\t\"kp_9_x_t4\",\t\"kp_9_y_t0\",\t\"kp_9_y_t1\",\t\"kp_9_y_t2\",\t\"kp_9_y_t3\",\n",
    "                    \t\"kp_9_y_t4\",\t\"position_a\",\t\"position_b\",\t\"position_c\",\t\"position_d\",\t\"hand_in_pocket\"]\n",
    "\n",
    "filtered_columns = [col for col in new_columns_order if col in combined_df.columns]\n",
    "combined_df = combined_df[filtered_columns]\n",
    "# combined_df = combined_df.astype(int)\n",
    "\n",
    "for col in combined_df.columns:\n",
    "    if 'x' in col.lower():\n",
    "        combined_df[col] = combined_df[col].astype(int) #for not normalized keypoint to convert them into numbers like 271,542\n",
    "        combined_df[col] = pd.to_numeric((combined_df[col] / 1280), errors='coerce')\n",
    "        combined_df[col] = combined_df[col].apply(lambda x: -1 if x == 0 else x)\n",
    "        combined_df[col] = combined_df[col].round(3) # for notmalized keypoints to convert them till 3 decimal places \n",
    "    elif 'y' in col.lower():\n",
    "        combined_df[col] = combined_df[col].astype(int) #for not normalized keypoint to convert them into numbers like 271,542\n",
    "        combined_df[col] = pd.to_numeric((combined_df[col] / 720), errors='coerce')\n",
    "        combined_df[col] = combined_df[col].apply(lambda x: -1 if x == 0 else x)\n",
    "        combined_df[col] = combined_df[col].round(3) # for notmalized keypoints to convert them till 3 decimal places \n",
    "    \n",
    "\n",
    "combined_df.to_csv(output_csv, index=False)\n",
    "# combined_df.to_csv(df, index=False)\n",
    "print(f\"✅ Combined CSV saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc320d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
